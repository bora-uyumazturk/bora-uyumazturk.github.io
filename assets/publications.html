<!DOCTYPE html>
<html lang='en'>
    <head>
        <title>Publications</title>
        <link rel="stylesheet" type="text/css" href="../style.css">
   </head>

    <body>
        <div class="Header">
          <a class="Header-name" href="../index.html">Bora Uyumazturk</a>
          <nav class="Header-nav">
            <a href="publications.html">Publications</a>
            <a href="side-projects.html">Side Projects</a>
            <a href="reading.html">Reading</a>
            <a href="../index.html">About</a>
          </nav>
          <nav class="Header-social">
            <a href="https://twitter.com/notsleepingturk">
              <img class="social-icon" src="images/twitter.svg">
            </a>
          </nav>
        </div>

        <div class="Content">

          <h2>Publications</h2>

          <div class="publication-title">Impact of a deep learning assistant on the histopathologic classification of liver cancer</div>
          <div>
            with Amirhossein Kiani, Pranav Rajpurkar, Alex Wang, Robyn L. Ball, Rebecca Gao, Yifan Yu, Erik Jones, Curtis P. Langlotz, Brock Martin, Gerald J. Berry, Michael G. Ozawa, Florette K. Hazard, Ryanne A. Brown, Simon B. Chen, Mona Wood, Libby S. Allard, Lourdes, Ylagan , Andrew Y. Ng, Jeanne Shen
          </div>
          <p>
            <i/>npj Digital Medicine</i>, 3, (1), pages 1-8, February, 2020. Number: 1 Publisher: Nature Publishing Group.
          </p>
          <p>
            <i/>ML4H Workshop, NeurIPS 2019.</i>
          </p>
          <p>
            In this paper, we developed a deep learning assistant for distinguishing between subtypes of primary liver carcinoma and evaluated it in a retrospective cross-over study involving eleven pathologists of different specialties and experience levels. We found that, despite the model itself having high accuracy on an independent test set, only nine of eleven pathologists experienced an improvement in accuracy (in fact, two pathologists performed worse). We found that pathologists on average performed four times better (in terms of odds ratio)  when the model provided the correct diagnosis than without the model. However, when the model provided the wrong diagnosis, they performed about a third as well as when they were on their own. These results suggest the potential presence of automation bias. We conclude that future research should explore effect of various design decisions on joint human-AI performance of deep learning-based diagnostic support systems.
            <br/>[<a href="https://www.nature.com/articles/s41746-020-0232-8">paper</a>] [<a href="https://arxiv.org/abs/1911.07372">extended abstract</a>] [<a href="https://github.com/stanfordmlgroup/lca-code">code</a>]
          </p>

          <br>

          <div class="publication-title">Consequences of Social Risk in Small and Moderately Sized Deliberative Democracies</div>
          <div>with Lilia Chang</div>
          <p>
            <i/><a href="https://www.radicalxchange.org/2019-conference/", target="_blank">RadicalxChange 2019</a></i>
          </p>
          <p>
            We analyzed the voting behavior of indivudals participating in public, consensus voting schemes from a game theoretic perspective. We presented a model of public voting incorporating social pressures and proved the existence of an equilibrium in which truthfulness of votes decays as number of individuals increases in consensus voting. We then compared qualitative predictions from model with empirical evidence from a community at Stanford which implements consensus voting. Our findings suggest that instead of acting as a vehicle for change, public consensus voting may in fact reinforce status quo.
            <br/>[<a href="assets/majority_minority.pdf">paper</a>]
          </p>
        </div>
    </body>

</html>
